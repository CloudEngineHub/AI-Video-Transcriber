# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Custom OpenAI Base URL (for proxy or alternative endpoints)
# If using Ollama, set this to your Ollama API endpoint, e.g., http://localhost:11434/v1
OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Ollama Model Name
# If using Ollama, specify the model name you want to use, e.g., llama3, qwen:7b, etc.
# This will override the default OpenAI model used for summarization and translation.
OLLAMA_MODEL_NAME=

# Server Configuration (Optional)
HOST=0.0.0.0
PORT=8000

# Whisper Model Configuration (Optional)
# Options: tiny, base, small, medium, large
WHISPER_MODEL_SIZE=base
